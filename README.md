# Diehl & Cook 2015 Code for Brian 2

This is an updated version of the original code written by Peter U. Diehl to work with Brian 2 and Python 3.

Original Paper: Diehl & Cook, 'Unsupervised learning of digit recognition using spike-timing-dependent plasticity', 2015  
Link: https://www.frontiersin.org/journals/computational-neuroscience/articles/10.3389/fncom.2015.00099/full

Original Code: https://github.com/peter-u-diehl/stdp-mnist

Updated By: Genevieve Fahey, July 2024 (no affiliation with original authors)


## Setup

This code requires Python 3, Brian 2, and the MNIST dataset.

Installation instructions for Brain 2 can be found here: https://briansimulator.org/

The MNIST dataest can be found here: http://yann.lecun.com/exdb/mnist/  
Create a folder named 'MNIST' alongside the python files and extract the four .gz dataset files into it.
If you wish to place them in a different folder, be sure to update the MNIST_data_path variable in the 'Diehl&Cook_spiking_MNIST_B2.py' and 'Diehl&Cook_MNIST_evaluation_B2.py' files. 


## Files

- Diehl&Cook_spiking_MNIST_B2.py: main file containing simulation code for training and testing the spiking neural networks.
- Diehl&Cook_MNIST_evaluation_B2.py: uses result files saved to the 'activity/' folder after running a simulation in the above code. Uses the highest average classifier as described in the paper to determine classification accuracy of the specified network.
- Diehl&Cook_MNIST_random_conn_generator_B2.py: appears to generate connections for use in simulation code. Not required for training or testing.
- weights/WeightReadout_B2.py: appears to print and plot weight files, some of which do not appear to be part of the original code. Not required for training and testing.
- random/\*.npy files: contain initial weights for the network.
- weights/\*.npy files: contain pre-trained weights included in the original repository.


## Instructions for Use

For training a network:
1. Set test_mode = False on line 203 in 'Diehl&Cook_spiking_MNIST_B2.py'.
2. Set save_name to your preferred filename suffix for the saved weights and theta values. These will be saved to the 'weights/' folder.
3. Run the code.

For testing a network:
1. Set test_mode = True on line 203 in 'Diehl&Cook_spiking_MNIST_B2.py'.
2. Set load_name = save_name to use your trained weights. Set load_name = '' to run a test using the pre-trained weights from the original repository.
3. Run the code.
4. Result files for classification will be saved in the 'activity/' folder with num_examples as a suffix. Be sure to back them up somewhere safe if you do not wish for these to be over-written every time a new simulation is performed.

For evaluating a network's classification performance:
1. In 'Diehl&Cook_MNIST_evaluation_B2.py' set training_ending = 'x' and testing_ending = 'y' where x is the number of examples used during training and y is the number of examples used during testing of the network. The defaults are x = '60000' and y = '10000'. To run the faster demo version as per the original code, set both to '10000' and read the note below.
2. Run the code.

Evaluating the network uses the highest average classifier as described in the paper. The original code (and the updated version) both default to using the results only from the test run (instead of both the training and testing runs) which can produce a slight increase in performance as noted in the original repository:

*"Note:
In this simple demo the performance is evaluated using neuron assignments of the test set. This leads to a slight increase in performance but violates good practice in machine learning. The results presented in the paper did NOT use the test set to determine neuron assignments. Instead the assignments were generated by running the same script in testing mode but using the 60000 examples of the training set to determine neuron assignments (this can be done by changing line 85 in "Diehl&Cook_MNIST_evaluation.py" to training_ending = '60000')."*

The original repository states that testing and evaluating the pre-trained weights should result in an accuracy of around 91.56%.  
Training and testing a new network should result in around 89% with the given parameters. 


## FAQ

- *How can I run this for networks with a different number of neurons?*  
Change n_e on line 239 to your desired number of neurons. Uncomment line 403 and comment out lines 404 and 405. This will force the code to generate random weights to initialise the network rather than load the pre-generated 400 weights from a file.

- *Does this include all four of the STDP rules from the paper?*  
No, it only includes the Triplet STDP rule.

- *What are the hyperparameters for the other rules?*  
They were not included in the paper or the original code. It is not clear what the STDP_offset variable was originally intended for.

- *The simulation is very slow on my computer, how can I make it faster?*  
Consider changing the default clock step size for the simulation. This will have an effect on the precision of the numerical integration calculations but for values near the default will still produce similar accuracy results. More information on the default clock can be found in the Brian 2 documentation: https://brian2.readthedocs.io/en/stable/user/running.html


## Update Notes

All .py files have been updated. All .npy files from original repository are included here without changes.

The original code used dense connections in Brian for the recurrent exc->inh and inh->exc connections and then loaded in .npy files of weights to simulate the one-to-one and i!=j connectivity. This version uses the built-in Brian 2 one-to-one and i!=j connection support with the weight values found in the .npy files.

For creating network populations: the code no longer loops through population names. Use the new load_name and save_name variables for filenames.  
To use the random initial weights file for training as per the original code, set load_name = ''.  
To use the weight files that you have trained yourself, set load_name = save_name.

Not all plotting features have been supported in the update. The code still successfully plots the spike monitors at the end of the file. Plotting for the plot_2d_input_weights() and plot_performance() functions as well as the population rate monitors and spike monitor before simulation begins are not supported. These have been commented out in the code so their functionality is still visible. They are not required for recreating the experiments in the paper.

Update 26 May 2025: I have changed the eqs_stdp_ee equations for STDP learning to specify (event-driven) processing instead of (clock-driven) from the original code. This greatly improves execution times during training. 


## Observations

The original normalize_weights() function can produce a division by zero error if this code is used to run other network experiments.

The simulation code may take many hours to run. Consider running for a smaller value of num_examples first to verify that it is working for you.
